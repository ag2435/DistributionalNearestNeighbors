{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heartsteps Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the Heartsteps v1 data to satisfy two primary criterion: (1) alignment of study day and decision slot across users and (2) restructuring of the data to match the distributional nearest neighbors framework. More information about this structure can be found later in the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jbsteps.csv` file contains step data for (roughly) every minute that trial partipants were wearing their Jawbone step tracker. We select the columns of interest and index the dataframe by the user index and the time that steps were recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the 5 minute observations\n",
    "df_steps = pd.read_csv(\"jbsteps.csv\")\n",
    "df_steps = df_steps[[\"user.index\", \"steps.utime\", \"steps\", \"study.day.nogap\"]]\n",
    "df_steps[\"steps.utime\"] = pd.to_datetime(df_steps[\"steps.utime\"])\n",
    "#creeate multi-index\n",
    "df_steps = df_steps.set_index(['user.index', 'steps.utime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `suggestions.csv` file contains data for each notification slot during all user trials. There are 5 notification slots per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suggestions = pd.read_csv(\"suggestions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the columns of interest and drop rows containing nan for crucial columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sugg_sel = df_suggestions[[\"user.index\", 'decision.index.nogap', 'sugg.select.utime','sugg.decision.utime', 'sugg.select.slot', 'avail', 'send', 'send.active', 'send.sedentary']]\n",
    "df_sugg_sel['sugg.decision.utime'] = pd.to_datetime(df_sugg_sel['sugg.decision.utime'])\n",
    "df_sugg_sel = df_sugg_sel.dropna(subset=[\"sugg.decision.utime\", \"sugg.select.utime\", \"user.index\"])\n",
    "df_sugg_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we group the step observations into 5 minute chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(x):\n",
    "  if len(pd.Series.mode(x) > 1):\n",
    "    return pd.Series.mode(x, dropna=False)[0]\n",
    "  else:\n",
    "    return pd.Series.mode(x, dropna=False)\n",
    "\n",
    "df_5min = df_steps.groupby([pd.Grouper(freq='5min', level = \"steps.utime\", label = \"right\"), \n",
    "pd.Grouper(level = \"user.index\")], sort = False).agg({'steps': 'sum', 'study.day.nogap': lambda x : get_mode(x)}).reset_index()\n",
    "df_5min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we expand the time periods to include all times of day, not just the times that steps were measured.\n",
    "This is necessary as step data collection often occured in spurts. This means that time periods in which a notification was sent may not be represented in the original data frame, making it difficult to merge `df_suggestions` and `df_5min`. Time periods where steps were not tracked are imputed with 0 steps. This may not accurately represent the user's real step count in that period, but it is a limitation imposed by the data. Future work may fold in the Google Steps tracking information, which is more complete but potentially inaccurate approximation of user step activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out the 5 minute intervals between measurements\n",
    "from datetime import date, timedelta\n",
    "def reind_id(df_u):\n",
    "    rng = pd.date_range(min(df_u.index.astype('datetime64[ns]')), max(df_u.index.astype('datetime64[ns]')) + timedelta(days = 1), \n",
    "    normalize = True, inclusive = \"both\", freq = \"5T\")\n",
    "    rng = rng[rng.indexer_between_time('00:00', '23:55')]\n",
    "    #print(rng)\n",
    "    df_reind = df_u.reindex(rng)\n",
    "    df_reind['user.index'] = df_reind['user.index'].ffill().bfill()\n",
    "    df_reind['study.day.nogap'] = df_reind['study.day.nogap'].bfill().ffill()\n",
    "    df_reind['steps'] = df_reind['steps'].fillna(0)\n",
    "    return df_reind\n",
    "\n",
    "df_5min_ind = df_5min.set_index('steps.utime')\n",
    "\n",
    "df_expand5min = df_5min_ind.groupby('user.index', group_keys = False).apply(lambda df_u:reind_id(df_u))\n",
    "df_expand5min = df_expand5min.reset_index(names = \"steps.utime\")\n",
    "\n",
    "df_expand5min['user.index'] = df_expand5min['user.index'].astype(\"int64\")\n",
    "print(df_expand5min)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we merge `df_sugg_sel` with `df_expand5min`. The merge will provide notification information for each decision slot. Notifications are grouped into the 5 minute block that occurs after the decision was made. For example, a decision made at 8:31:50 AM would be joined with the 8:35 AM time slot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge as of on steps.utime with the time of each notification time period. by = user.index, tolerance = pd.Timedelta(\"5min\"), check for direction\n",
    "df_merged = pd.merge_asof(\n",
    "    df_expand5min.sort_values(by ='steps.utime'),\n",
    "    df_sugg_sel.sort_values(by = 'sugg.decision.utime'),\n",
    "    left_on=\"steps.utime\",\n",
    "    right_on=\"sugg.decision.utime\",\n",
    "    by=\"user.index\",\n",
    "    tolerance=pd.Timedelta(\"5min\"),\n",
    "    allow_exact_matches=False,\n",
    "    direction = 'backward'\n",
    ").sort_values(by = [\"user.index\", \"steps.utime\"]).reset_index(drop = True)\n",
    "\n",
    "#df_merged[df_merged[\"user.index\"] == 1][df_merged[\"sugg.select.utime\"] == \"2015-09-15 10:30:00\"]\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    #display(df_merged[df_merged['user.index'] == 36][7000:7150])\n",
    "    \n",
    "# want to treat vacation days as maximally normal observation periods -> they are not notification periods\n",
    "df_merged['sugg.select.slot'] = np.where(df_merged['decision.index.nogap'].isna(), np.nan, df_merged['sugg.select.slot'])\n",
    "display(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take 12 rows after each decision period. This represents 1 hour of step data following each (potential) notification. We drop duplicate rows as some notifications fell within one hour of each other, creating overlapping time ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab 12 rows after each notification period\n",
    "def takeRange(df: pd.DataFrame, range: int): \n",
    "  idx = df.index.get_indexer_for(df[np.argsort(pd.notna(df[\"sugg.select.slot\"]), )].index)\n",
    "  ranges = [np.arange(i, min(i + range + 1, len(df))) for i in idx]\n",
    "  #print(\"Next Df\")\n",
    "  # for i in ranges:\n",
    "  #  num_overlap = len(df.iloc[i][pd.notna(df['sugg.select.slot'])])\n",
    "  #  if (num_overlap > 1):\n",
    "  #   print(\"Overlap: \") \n",
    "  #   print(df.iloc[i])\n",
    "  return df.iloc[np.concatenate(ranges)]\n",
    "# find ids of the notification period -> this only happens when sugg.select.slot is not na\n",
    "#idx = df_merged.index.get_indexer_for(df_merged[pd.notna(df_merged['sugg.select.slot'])].index)\n",
    "# we want 1 hour of data after the notification period, so 12 slots\n",
    "#df_merged.iloc[np.unique(np.concatenate([np.arange(i, min(i+n+1, len(df_merged)))\n",
    "                                            #for i in idx]))]\n",
    "df_merged_cut = df_merged.groupby('user.index', group_keys = False).apply(lambda df_u:takeRange(df_u, 12)).reset_index(drop = True)\n",
    "df_merged_cut_nd = df_merged_cut.drop_duplicates()\n",
    "\n",
    "# set up column for study day\n",
    "df_merged_cut_nd['study_day'] = np.nan\n",
    "df_merged_cut_nd['new_slot'] = np.nan\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#df_merged_cut.groupby('user.index').apply(lambda df_u: df_u.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We artificially \"fix\" the decision slots and study day columns. The adjustments done below counteract abnormalities in the data, such as a notification scheduled to sent at slot 4 but was instead sent at slot 1. The need for a new study day column arises from mismatches in time between recorded steps and the notifications. Since study days were only measured explicitly alongside recorded steps, the notifications would often have the incorrect study day if multiple notifications were sent before any steps were recorded. To reduce these study day miscalculations, we manually create new decision slots based on the existing patterns and base study days entirely on a sequence of 5 decision slots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slots(df):\n",
    "  most_rec_slot = 0.0\n",
    "  for ind, row in df.iterrows():\n",
    "    curr_slot = row['sugg.select.slot']\n",
    "    if not np.isnan(curr_slot):\n",
    "      if most_rec_slot != 5.0 and curr_slot != most_rec_slot + 1 and most_rec_slot != 0.0:\n",
    "        df.at[ind, 'new_slot'] = most_rec_slot + 1\n",
    "        most_rec_slot += 1\n",
    "      elif most_rec_slot == 5.0 and curr_slot != 1:\n",
    "        df.at[ind, 'new_slot'] = 1\n",
    "        most_rec_slot = 1\n",
    "      else:\n",
    "        df.at[ind, 'new_slot'] = curr_slot\n",
    "        most_rec_slot = curr_slot\n",
    "      #print(curr_study_day)\n",
    "      #df.at[ind,'study_day'] = curr_study_day\n",
    "      #print(df.loc[ind]['study_day'])\n",
    "  return df\n",
    "def study_day(df):\n",
    "  most_rec_slot = 1.0\n",
    "  curr_study_day = 1\n",
    "  for ind, row in df.iterrows():\n",
    "    curr_slot = row['new_slot']\n",
    "    if not np.isnan(curr_slot):\n",
    "      if most_rec_slot == 5.0 and curr_slot == 1:\n",
    "        curr_study_day += 1\n",
    "      most_rec_slot = curr_slot\n",
    "      #print(curr_study_day)\n",
    "      df.at[ind,'study_day'] = curr_study_day\n",
    "\n",
    "  return df\n",
    "df_slot = df_merged_cut_nd.groupby('user.index', group_keys = False).apply(lambda df_u: create_slots(df_u))\n",
    "df_study_day = df_slot.groupby('user.index', group_keys = False).apply(lambda df_u: study_day(df_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slot[(df_slot[\"sugg.select.slot\"] != df_slot[\"new_slot\"]) & pd.notna(df_slot[\"avail\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "  display(df_study_day[(df_study_day['user.index'] == 13) & (pd.notna(df_study_day['avail']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the maximum study day so that we can pad the remaining trials to that study period. We also set the index of the final data frame as a combination of the user index, study day, and the decision slot of the day. In theory, this index is unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max study day\n",
    "print(max(df_study_day['study.day.nogap']))\n",
    "print(df_study_day['study_day'].max())\n",
    "\n",
    "#print(max_study_day)\n",
    "df_final = df_study_day.set_index(['user.index', 'study_day', 'new_slot'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `transform_dnn`, we iteratively search for the set of measurements for each user x study day x day decision slot combination. If such a measurement exists, the missingness of the data is determined by whether or not a notification was sent. If it does not, the missingness could either be treated as the user not being available (A = 2) or the data not being observed (A = 0). Further, we only use `send.sedentary` as an indicator of treatment. Future work could combine `send.sedentary` and `send.active`. TODO: several questions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dnn(df, users = 37, max_study_day = 52, day_dec = 5, num_measurements = 12):\n",
    "  \"\"\"\n",
    "\n",
    "  \"\"\"\n",
    "  final_M = np.zeros((users, max_study_day, day_dec, num_measurements))\n",
    "  final_A = np.zeros((users, max_study_day, day_dec))\n",
    "  for user in range(1, users + 1):\n",
    "    for day in range(1, max_study_day + 1):\n",
    "      for slot in range(1, day_dec + 1):\n",
    "        try:\n",
    "          df_uds = df.loc[user, day, slot]\n",
    "          ind = df.index.get_indexer_for(df_uds.index)\n",
    "          if len(ind) > 1:\n",
    "            print(ind)\n",
    "            display(df.iloc[ind])\n",
    "          df_rng = df.iloc[np.arange(ind, min(ind + num_measurements, len(df)))]\n",
    "          if df.iloc[ind]['avail'].bool():\n",
    "            # only take send.sedentary as the treatment indicator, could use send.active later\n",
    "            val = df.iloc[ind][\"send.sedentary\"]\n",
    "            if len(val) >1:\n",
    "              print(val)\n",
    "            conv_val = val if val.notna().bool() else df.iloc[ind][\"send\"]\n",
    "            final_A[user - 1,day - 1, slot - 1] = int(conv_val)\n",
    "          else:\n",
    "            final_A[user - 1, day - 1, slot - 1] = 2\n",
    "\n",
    "          measurements = df_rng['steps'].to_numpy()\n",
    "          if len(measurements) == num_measurements:\n",
    "            final_M[user - 1, day - 1, slot - 1] = measurements\n",
    "          else:\n",
    "            m_pad = np.pad(measurements, (0, num_measurements -  len(measurements)),\n",
    "            constant_values = np.nan)\n",
    "            final_M[user - 1, day - 1, slot - 1] = m_pad\n",
    "        except KeyError as e:\n",
    "          # this user is missing the study day/day ind\n",
    "          print(repr(e))\n",
    "          final_A[user - 1, day - 1, slot - 1] = 0 # do we consider missing data as not observed or not available\n",
    "          final_M[user - 1, day - 1, slot - 1] = np.full(num_measurements, np.nan)\n",
    "  final_M = final_M.reshape((users, max_study_day * day_dec, num_measurements))\n",
    "  final_A = final_A.reshape((users, max_study_day * day_dec))\n",
    "  return final_M, final_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we transform the data and show the masking matrix to see the missingness pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final.loc[1, 20, 1.0]\n",
    "M_hs, A_hs = transform_dnn(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import matshow\n",
    "matshow(A_hs, aspect = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"heartsteps_mask\", A_hs)\n",
    "np.save(\"heartsteps_data\", M_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "  display(df_merged_cut[df_merged_cut['user.index'] == 4].iloc[1600:1680])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df_merged.index.get_indexer_for(df_merged[pd.notna(df_merged[\"avail\"])].index)\n",
    "trial = df_merged.iloc[idx].reset_index(drop = True)\n",
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_sel = trial[[\"user.index\", \"decision.index.nogap\", \"sugg.select.utime\", \"sugg.decision.utime\", \"sugg.select.slot\", \"avail\", \"send\", \"send.active\", \"send.sedentary\"]]\n",
    "trial_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sugg_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = pd.merge(trial_sel, df_sugg_sel, on=['user.index', 'sugg.select.utime'], how='outer',\n",
    "#                suffixes=('_df1', '_df2')).set_index(['user.index', 'sugg.select.utime'])\n",
    "\n",
    "# out.columns = pd.MultiIndex.from_tuples(out.columns.str.split('_').map(tuple)) \\\n",
    "#                            .swaplevel()\n",
    "\n",
    "# out = out['df1'].compare(out['df2'])\n",
    "\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
